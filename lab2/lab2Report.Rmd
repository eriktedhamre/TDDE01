---
title: "lab1"
author: "Erik Tedhamre"
date: "8 December 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

## Assignment 1.1
```{r 1.1}
library("ggplot2")
library("MASS")
data <- data.frame(read.csv("australian-crabs.csv"))
ggplot(data = data, mapping = aes(CL, RW, color = sex)) + geom_point()
```
A plot of carapace length versus rear width where the observations are colored by sex. Looking at the graph the data seems reasonably easy to classify by linear discriminant analysis. Because there seems to be a line between the two sexes.

## Assignment 1.2
```{r 1.2}
lda.model1 <- lda(sex ~ CL + RW, data = data)
lda.predict1 <- predict(lda.model1, data)
ggplot.0.5 <- ggplot(data = data, mapping = aes(CL, RW, color = lda.predict1$class, shape = sex )) + geom_point()
ggplot.0.5
mcr.0.5 <- mean(lda.predict1$class != data$sex)
```
The missclassification rate for the linear discriminant analysis is **0.035**. This is pretty reasonable considering we saw on the original graph that there was one area with a bit of an overlap. If this is good enough for actual use is hard to say, it mostly depends on how much we would lose on an incorrect classification.

## Assignment 1.3
```{r 1.3.1}
lda.model2 <- lda(sex ~ CL + RW, data = data, prior = c(Female = 0.1, Male = 0.9))
lda.predict2 <- predict(lda.model2, data)
ggplot(data = data, mapping = aes(CL, RW, color = lda.predict2$class, shape = sex )) + geom_point()
```
The number of males increased since we are assuming a wheighted distribution. Especially the areas containing both types of observations are now classified as only males instead of both.

```{r 1.3.2}
mcr.0.9 <- mean(lda.predict2$class != data$sex)
```
The missclassification rate for the weighted linear discriminant analysis is **0.08**.
## Assignment 1.4
```{r 1.4.1}
glm.model <- glm(as.factor(sex) ~ CL + RW, family = binomial, data = data)
glm.predict <- predict(glm.model, data, type = 'response')
mcr.glm <- mean(glm.predict != data$sex)
```
The missclassification rate is **0.035** which is the same as the original linear discriminant analysis.

```{r 1.4.2}
glm.predict.0.5 <- ifelse(glm.predict > 0.5, "Male", "Female")
glm.slope <- coef(glm.model)[2]/(-coef(glm.model)[3])
glm.intercept <- coef(glm.model)[1]/(-coef(glm.model)[3])
ggplot.0.5 + geom_abline(slope = glm.slope, intercept = glm.intercept)
```
The decision line is drawn in the graph.

## Assignment 2
Splitting the data into partitions
```{r 2.1.1}
library("e1071")
library("MASS")
library("tree")
library("ggplot2")
setwd("~/TDDE01/lab2")
data.credit <- data.frame(read.csv("creditscoring.csv"))
n=dim(data.credit)[1]
set.seed(12345) 
id=sample(1:n, floor(n*0.5)) 
train=data.credit[id,]
id1=setdiff(1:n, id)
set.seed(12345) 
id2=sample(id1, floor(n*0.25)) 
valid=data.credit[id2,]
id3=setdiff(id1,id2)
test=data.credit[id3,]
```

```{r echo = FALSE}
tree.fit.dev <- tree(good_bad ~., data = train, split = "deviance")
tree.fit.gini <- tree(good_bad ~., data = train, split = "gini")
```
The models used in calculating the following confusion matrices.

```{r echo = FALSE}
pred.dev.train <- predict(tree.fit.dev, newdata = train, type="class")
table(train$good_bad, pred.dev.train)
```
Confusion matrix for deviance on train data.
```{r echo = FALSE}
pred.dev.test <- predict(tree.fit.dev, newdata = test, type="class")
table(test$good_bad, pred.dev.test)
```
Confusion matrix for deviance on test data.
```{r echo = FALSE}
pred.gini.train <- predict(tree.fit.gini, newdata = train, type="class")
table(train$good_bad, pred.gini.train)
```
Confusion matrix for gini on train data.
```{r echo = FALSE}
pred.gini.test <- predict(tree.fit.gini, newdata = test, type="class")
table(test$good_bad, pred.gini.test)
```
Confusion matrix for gini on test data.
The confusion matrix is the best for deviance compared to gini based on the number of correct predictions for the test data.

## Assignment 2.3
```{r echo = FALSE}
fit=tree(good_bad~., data=train)
set.seed(12345)
max.size <- 15
trainScore=rep(0,max.size)
testScore=rep(0,max.size)
for(i in 2:max.size) {
  prunedTree=prune.tree(fit,best=i)
  pred=predict(prunedTree, newdata=valid, type="tree")
  trainScore[i]=deviance(prunedTree)
  testScore[i]=deviance(pred)
}
plot(2:max.size, trainScore[2:max.size], type="b", col="red", ylim=c(250,400), xlab = "Number of leaves", ylab = "Score")
points(2:max.size, testScore[2:max.size], type="b", col="blue")
```

Looking at the graph we see a minimum value for 4.

```{r echo = FALSE}
finalTree=prune.tree(fit, best=4)
plot(finalTree)
```

Something about the tree structure. The optimal depth of the tree is three which can be seen in the graph.

```{r echo = FALSE}
Yfit=predict(finalTree, newdata=valid, type = "class")
table(valid$good_bad,Yfit)
```
Confusion matrix for the validation data for the tree data

```{r echo = FALSE}
summary(finalTree)
```
As seen above the variables used in the tree are "savings", "duration" and "history".
```{r echo = FALSE}
fit.bayes=naiveBayes(good_bad~., data=train)
Yfit.bayes.train=predict(fit.bayes, newdata=train)
Yfit.bayes.test=predict(fit.bayes, newdata=test)
table(Yfit.bayes.train, train$good_bad)
table(Yfit.bayes.test, test$good_bad)
```

The tree prediction is a bit better than the bayesian prediction.

```{r echo = FALSE}
set.seed(12345)

createROCmatrix <- function(pred, pi.vector){
  tpr.vector = numeric()
  fpr.vector = double()
  
  for (pi.value in pi.vector) {
    predict.pi <- ifelse(pred[,2] > pi.value, "good", "bad")
    TP <- length(which(predict.pi == "good" & test$good_bad == "good"))
    TN <- length(which(predict.pi == "bad" & test$good_bad == "bad"))
    FP <- length(which(predict.pi == "good" & test$good_bad == "bad"))
    FN <- length(which(predict.pi == "bad" & test$good_bad == "good"))
    
    tpr.vector <- append(tpr.vector, TP/(TP+FN))
    fpr.vector <- append(fpr.vector, FP/(FP+TN))
  }
  return(data.frame(pi.vector, tpr.vector, fpr.vector))
}

Yfit.tree.test=predict(finalTree, newdata=test)
pi.vector <- seq(0.05, 0.95, 0.05)

tree.predict <- predict(finalTree, newdata = test)
fit.bayes <- naiveBayes(good_bad~., data=train)
bayes.predict <- predict(fit.bayes, newdata = test, type = "raw")

tree.ROC.matrix <- createROCmatrix(tree.predict, pi.vector)
bayes.ROC.matrix <- createROCmatrix(bayes.predict, pi.vector)

ggplot(data = NULL, aes(col = classifier), xlab = "FPR", ylab = "TPR") +
  geom_point(data = tree.ROC.matrix, aes(x = fpr.vector, y = tpr.vector, col="Tree")) + 
  geom_line(data = tree.ROC.matrix, aes(x = fpr.vector, y = tpr.vector, col="Tree")) +
  geom_point(data = bayes.ROC.matrix, aes(x = fpr.vector, y = tpr.vector, col="Bayes")) + 
  geom_line(data = bayes.ROC.matrix, aes(x = fpr.vector, y = tpr.vector, col="Bayes")) 

```
Graph of radius of convergence


```{r echo = FALSE}
loss_matrix <- matrix(data = c(0,1,10,0), nrow = 2, ncol = 2)
bayes.loss.predict <- ifelse(bayes.predict[,2]/bayes.predict[,1] > loss_matrix[3]/loss_matrix[2], "good", "bad")
table(test$good_bad, bayes.loss.predict)
```
Weird table probably incorrect.